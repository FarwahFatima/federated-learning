{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9931340,"sourceType":"datasetVersion","datasetId":6104759},{"sourceId":9933901,"sourceType":"datasetVersion","datasetId":6106774}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import zipfile\nimport os\n\n# Path to the uploaded .zip file\nzip_path = '/kaggle/input/your-dataset-name/your-file.zip'  # Replace with your actual file path\nextract_path = '/kaggle/working/dataset-folder'  # The path where you want to extract the files\n\n# Extract the .zip file\nwith zipfile.ZipFile(zip_path, 'r') as zip_ref:\n    zip_ref.extractall(extract_path)\n\n# List extracted files\nprint(os.listdir(extract_path))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport numpy as np\nfrom torchvision import models, transforms\nfrom torch.utils.data import DataLoader\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom torchvision import datasets\nfrom sklearn.metrics import accuracy_score\nimport os\n\n# Device setup\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# Transformations\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\n# Paths to dataset (update for each dataset)\ntrain_dir = r\"/kaggle/input/d/fatimafarwah/fyp-dataset/idrid_segmented/train\"\nvalid_dir = r\"/kaggle/input/d/fatimafarwah/fyp-dataset/idrid_segmented/valid\"\ntest_dir = r\"/kaggle/input/d/fatimafarwah/fyp-dataset/idrid_segmented/test\"\nsave_path = \"/kaggle/working/best_model_idrid.pth\"\n\n# Hyperparameters\nnum_epochs = 50\npatience = 5\nbatch_size = 32\nlearning_rate = 0.0001\n\n# Load datasets\ntrain_dataset = datasets.ImageFolder(root=train_dir, transform=transform)\nvalid_dataset = datasets.ImageFolder(root=valid_dir, transform=transform)\ntest_dataset = datasets.ImageFolder(root=test_dir, transform=transform)\n\n# Compute class weights\nlabels = [label for _, label in train_dataset.samples]\nclass_weights = compute_class_weight('balanced', classes=np.unique(labels), y=labels)\nclass_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n\n# Data loaders\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nvalid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n\n# Model setup\nmodel = models.mobilenet_v2(weights='IMAGENET1K_V1')\nfor param in model.parameters():\n    param.requires_grad = False  # Freeze all layers except classifier\n\n# Modify classifier for binary classification\nmodel.classifier = nn.Sequential(\n    nn.Dropout(0.3),\n    nn.Linear(model.last_channel, 512),\n    nn.ReLU(inplace=True),\n    nn.BatchNorm1d(512),\n    nn.Dropout(0.3),\n    nn.Linear(512, 1)  # Binary output (logit)\n)\nfor param in model.classifier.parameters():\n    param.requires_grad = True\nmodel = model.to(device)\n\n# Loss function and optimizer\ncriterion = nn.BCEWithLogitsLoss(pos_weight=class_weights[1])\noptimizer = optim.Adam(model.classifier.parameters(), lr=learning_rate)\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3, factor=0.1, verbose=True)\n\n# Training loop\nbest_val_loss = np.inf\nepochs_without_improvement = 0\n\nfor epoch in range(num_epochs):\n    model.train()\n    running_loss = 0.0\n    for inputs, labels in train_loader:\n        inputs, labels = inputs.to(device), labels.to(device).float()\n\n        optimizer.zero_grad()\n        outputs = model(inputs).squeeze()\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n\n    avg_train_loss = running_loss / len(train_loader)\n    print(f\"Epoch [{epoch+1}/{num_epochs}], Training Loss: {avg_train_loss:.4f}\")\n\n    # Validation\n    model.eval()\n    valid_loss = 0.0\n    valid_labels = []\n    valid_preds = []\n\n    with torch.no_grad():\n        for inputs, labels in valid_loader:\n            inputs, labels = inputs.to(device), labels.to(device).float()\n            outputs = model(inputs).squeeze()\n            loss = criterion(outputs, labels)\n            valid_loss += loss.item()\n\n            preds = torch.sigmoid(outputs) > 0.5\n            valid_labels.extend(labels.cpu().numpy())\n            valid_preds.extend(preds.cpu().numpy())\n\n    avg_valid_loss = valid_loss / len(valid_loader)\n    val_accuracy = accuracy_score(valid_labels, valid_preds)\n    print(f\"Validation Loss: {avg_valid_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}\")\n\n    # Adjust learning rate\n    scheduler.step(avg_valid_loss)\n\n    # Save the best model\n    if avg_valid_loss < best_val_loss:\n        best_val_loss = avg_valid_loss\n        epochs_without_improvement = 0\n        best_model_wts = model.state_dict()\n    else:\n        epochs_without_improvement += 1\n\n    # Early stopping\n    if epochs_without_improvement >= patience:\n        print(\"Early stopping triggered.\")\n        break\n\n# Load best weights\nmodel.load_state_dict(best_model_wts)\n\n# Save the best model\ntorch.save(model.state_dict(), save_path)\nprint(f\"Best model saved as '{save_path}'\")\n\n# Test the model\nmodel.eval()\ntest_labels = []\ntest_preds = []\n\nwith torch.no_grad():\n    for inputs, labels in test_loader:\n        inputs, labels = inputs.to(device), labels.to(device).float()\n        outputs = model(inputs).squeeze()\n\n        preds = torch.sigmoid(outputs) > 0.5\n        test_labels.extend(labels.cpu().numpy())\n        test_preds.extend(preds.cpu().numpy())\n\ntest_accuracy = accuracy_score(test_labels, test_preds)\nprint(f\"Test Accuracy: {test_accuracy:.2f}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import datasets, models, transforms\nfrom torch.utils.data import DataLoader\nfrom sklearn.utils.class_weight import compute_class_weight\nimport numpy as np\nimport os\nimport matplotlib.pyplot as plt\n\n# Device configuration\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Directories\ntrain_dir = r\"/kaggle/input/d/fatimafarwah/fyp-dataset/idrid_segmented/train\"\nvalid_dir = r\"/kaggle/input/d/fatimafarwah/fyp-dataset/idrid_segmented/valid\"\ntest_dir = r\"/kaggle/input/d/fatimafarwah/fyp-dataset/idrid_segmented/test\"\n\n# Data transformation\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\n# Datasets and DataLoaders\ntrain_dataset = datasets.ImageFolder(root=train_dir, transform=transform)\nvalid_dataset = datasets.ImageFolder(root=valid_dir, transform=transform)\ntest_dataset = datasets.ImageFolder(root=test_dir, transform=transform)\n\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\nvalid_loader = DataLoader(valid_dataset, batch_size=32, shuffle=False)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n\n# Class weights for imbalanced datasets\nlabels = [label for _, label in train_dataset.samples]\nclass_weights = compute_class_weight('balanced', classes=np.unique(labels), y=labels)\nclass_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n\n# Model setup\nmodel = models.mobilenet_v2(weights='IMAGENET1K_V1')\n\n# Freeze all parameters\nfor param in model.parameters():\n    param.requires_grad = False\n\n# Update classifier layer\nnum_classes = 2\nmodel.classifier = nn.Sequential(\n    nn.Dropout(0.3),\n    nn.Linear(model.last_channel, 256),\n    nn.ReLU(inplace=True),\n    nn.Dropout(0.3),\n    nn.Linear(256, num_classes)\n)\n\n# Unfreeze classifier parameters\nfor param in model.classifier.parameters():\n    param.requires_grad = True\n\n# Move model to device\nmodel = model.to(device)\n\n# Loss and optimizer\ncriterion = nn.CrossEntropyLoss(weight=class_weights)\noptimizer = optim.Adam(model.classifier.parameters(), lr=0.001)\n\n# Learning rate scheduler\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3, factor=0.1, verbose=True)\n\n# Early stopping setup\npatience = 5\nbest_val_loss = np.inf\nepochs_without_improvement = 0\nnum_epochs = 50\n\n# Training loop\ntrain_losses = []\nvalid_losses = []\nlearning_rates = []\n\nprint(\"Starting training...\\n\")\nfor epoch in range(num_epochs):\n    model.train()\n    running_loss = 0.0\n\n    for inputs, labels in train_loader:\n        inputs, labels = inputs.to(device), labels.to(device)\n\n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n\n    avg_train_loss = running_loss / len(train_loader)\n    train_losses.append(avg_train_loss)\n\n    # Validation\n    model.eval()\n    running_valid_loss = 0.0\n\n    with torch.no_grad():\n        for inputs, labels in valid_loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            running_valid_loss += loss.item()\n\n    avg_valid_loss = running_valid_loss / len(valid_loader)\n    valid_losses.append(avg_valid_loss)\n\n    # Learning rate scheduler step\n    scheduler.step(avg_valid_loss)\n    current_lr = optimizer.param_groups[0]['lr']\n    learning_rates.append(current_lr)\n\n    # Epoch summary\n    print(f\"Epoch [{epoch+1}/{num_epochs}] Summary:\")\n    print(f\"  Training Loss: {avg_train_loss:.4f}\")\n    print(f\"  Validation Loss: {avg_valid_loss:.4f}\")\n    print(f\"  Learning Rate: {current_lr:.6f}\")\n\n    # Early stopping\n    if avg_valid_loss < best_val_loss:\n        best_val_loss = avg_valid_loss\n        torch.save(model.state_dict(), '/kaggle/working/best_model.pth')\n        print(\"  Model improved. Saving model.\\n\")\n        epochs_without_improvement = 0\n    else:\n        epochs_without_improvement += 1\n        if epochs_without_improvement >= patience:\n            print(\"  Early stopping triggered. Ending training.\")\n            break\n\n# Load the best model and evaluate on the test set\nmodel.load_state_dict(torch.load('/kaggle/working/best_model.pth'))\nmodel.eval()\n\ncorrect = 0\ntotal = 0\nwith torch.no_grad():\n    for inputs, labels in test_loader:\n        inputs, labels = inputs.to(device), labels.to(device)\n        outputs = model(inputs)\n        _, predicted = torch.max(outputs, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\naccuracy = 100 * correct / total\nprint(f\"Accuracy on test set: {accuracy:.2f}%\")\n\n# Plotting\nplt.figure(figsize=(10, 5))\n\n# Plot training and validation loss\nplt.subplot(1, 2, 1)\nplt.plot(range(1, len(train_losses)+1), train_losses, label=\"Training Loss\")\nplt.plot(range(1, len(valid_losses)+1), valid_losses, label=\"Validation Loss\")\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.title('Training vs Validation Loss')\n\n# Plot learning rates\nplt.subplot(1, 2, 2)\nplt.plot(range(1, len(learning_rates)+1), learning_rates, label=\"Learning Rate\")\nplt.xlabel('Epochs')\nplt.ylabel('Learning Rate')\nplt.legend()\nplt.title('Learning Rate Over Epochs')\n\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T17:48:53.398713Z","iopub.execute_input":"2024-11-17T17:48:53.399107Z"}},"outputs":[{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/mobilenet_v2-b0353104.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v2-b0353104.pth\n100%|██████████| 13.6M/13.6M [00:00<00:00, 109MB/s] \n/opt/conda/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Starting training...\n\nEpoch [1/50] Summary:\n  Training Loss: 0.3158\n  Validation Loss: 0.2233\n  Learning Rate: 0.001000\n  Model improved. Saving model.\n\nEpoch [2/50] Summary:\n  Training Loss: 0.1963\n  Validation Loss: 0.2105\n  Learning Rate: 0.001000\n  Model improved. Saving model.\n\nEpoch [3/50] Summary:\n  Training Loss: 0.1607\n  Validation Loss: 0.1772\n  Learning Rate: 0.001000\n  Model improved. Saving model.\n\nEpoch [4/50] Summary:\n  Training Loss: 0.1489\n  Validation Loss: 0.1897\n  Learning Rate: 0.001000\nEpoch [5/50] Summary:\n  Training Loss: 0.1496\n  Validation Loss: 0.1544\n  Learning Rate: 0.001000\n  Model improved. Saving model.\n\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import datasets, models, transforms\nfrom torch.utils.data import DataLoader\nfrom sklearn.utils.class_weight import compute_class_weight\nimport numpy as np\nimport os\nimport matplotlib.pyplot as plt\n\n# Device configuration\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Directories\ntrain_dir = r\"/kaggle/input/d/fatimafarwah/fyp-dataset/idrid_segmented/train\"\nvalid_dir = r\"/kaggle/input/d/fatimafarwah/fyp-dataset/idrid_segmented/valid\"\ntest_dir = r\"/kaggle/input/d/fatimafarwah/fyp-dataset/idrid_segmented/test\"\n\n# Data transformation\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\n# Datasets and DataLoaders\ntrain_dataset = datasets.ImageFolder(root=train_dir, transform=transform)\nvalid_dataset = datasets.ImageFolder(root=valid_dir, transform=transform)\ntest_dataset = datasets.ImageFolder(root=test_dir, transform=transform)\n\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\nvalid_loader = DataLoader(valid_dataset, batch_size=32, shuffle=False)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n\n# Class weights for imbalanced datasets\nlabels = [label for _, label in train_dataset.samples]\nclass_weights = compute_class_weight('balanced', classes=np.unique(labels), y=labels)\nclass_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n\n# Model setup\nmodel = models.mobilenet_v2(weights='IMAGENET1K_V1')\n\n# Freeze all parameters\nfor param in model.parameters():\n    param.requires_grad = False\n\n# Update classifier layer\nnum_classes = 2\nmodel.classifier = nn.Sequential(\n    nn.Dropout(0.3),\n    nn.Linear(model.last_channel, 256),\n    nn.ReLU(inplace=True),\n    nn.Dropout(0.3),\n    nn.Linear(256, num_classes)\n)\n\n# Unfreeze classifier parameters\nfor param in model.classifier.parameters():\n    param.requires_grad = True\n\n# Move model to device\nmodel = model.to(device)\n\n# Loss and optimizer\ncriterion = nn.CrossEntropyLoss(weight=class_weights)\noptimizer = optim.Adam(model.classifier.parameters(), lr=0.001)\n\n# Learning rate scheduler\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3, factor=0.1, verbose=True)\n\n# Early stopping setup\npatience = 5\nbest_val_loss = np.inf\nepochs_without_improvement = 0\nnum_epochs = 50\n\n# Training loop\ntrain_losses = []\nvalid_losses = []\nlearning_rates = []\n\nprint(\"Starting training...\\n\")\nfor epoch in range(num_epochs):\n    model.train()\n    running_loss = 0.0\n\n    for inputs, labels in train_loader:\n        inputs, labels = inputs.to(device), labels.to(device)\n\n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n\n    avg_train_loss = running_loss / len(train_loader)\n    train_losses.append(avg_train_loss)\n\n    # Validation\n    model.eval()\n    running_valid_loss = 0.0\n\n    with torch.no_grad():\n        for inputs, labels in valid_loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            running_valid_loss += loss.item()\n\n    avg_valid_loss = running_valid_loss / len(valid_loader)\n    valid_losses.append(avg_valid_loss)\n\n    # Learning rate scheduler step\n    scheduler.step(avg_valid_loss)\n    current_lr = optimizer.param_groups[0]['lr']\n    learning_rates.append(current_lr)\n\n    # Epoch summary\n    print(f\"Epoch [{epoch+1}/{num_epochs}] Summary:\")\n    print(f\"  Training Loss: {avg_train_loss:.4f}\")\n    print(f\"  Validation Loss: {avg_valid_loss:.4f}\")\n    print(f\"  Learning Rate: {current_lr:.6f}\")\n\n    # Early stopping\n    if avg_valid_loss < best_val_loss:\n        best_val_loss = avg_valid_loss\n        torch.save(model.state_dict(), '/kaggle/working/best_model.pth')\n        print(\"  Model improved. Saving model.\\n\")\n        epochs_without_improvement = 0\n    else:\n        epochs_without_improvement += 1\n        if epochs_without_improvement >= patience:\n            print(\"  Early stopping triggered. Ending training.\")\n            break\n\n# Load the best model and evaluate on the test set\nmodel.load_state_dict(torch.load('/kaggle/working/best_model.pth'))\nmodel.eval()\n\ncorrect = 0\ntotal = 0\nwith torch.no_grad():\n    for inputs, labels in test_loader:\n        inputs, labels = inputs.to(device), labels.to(device)\n        outputs = model(inputs)\n        _, predicted = torch.max(outputs, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\naccuracy = 100 * correct / total\nprint(f\"Accuracy on test set: {accuracy:.2f}%\")\n\n# Plotting\nplt.figure(figsize=(10, 5))\n\n# Plot training and validation loss\nplt.subplot(1, 2, 1)\nplt.plot(range(1, len(train_losses)+1), train_losses, label=\"Training Loss\")\nplt.plot(range(1, len(valid_losses)+1), valid_losses, label=\"Validation Loss\")\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.title('Training vs Validation Loss')\n\n# Plot learning rates\nplt.subplot(1, 2, 2)\nplt.plot(range(1, len(learning_rates)+1), learning_rates, label=\"Learning Rate\")\nplt.xlabel('Epochs')\nplt.ylabel('Learning Rate')\nplt.legend()\nplt.title('Learning Rate Over Epochs')\n\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T19:37:06.377611Z","iopub.execute_input":"2024-11-17T19:37:06.378087Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Starting training...\n\nEpoch [1/50] Summary:\n  Training Loss: 0.2773\n  Validation Loss: 0.1998\n  Learning Rate: 0.001000\n  Model improved. Saving model.\n\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}